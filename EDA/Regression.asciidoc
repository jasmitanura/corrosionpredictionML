+*In[196]:*+
[source, ipython3]
----
#Import Library
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
----


+*In[197]:*+
[source, ipython3]
----
#Import Dataset
df = pd.read_csv("DATASETJASMITAbismillah.csv")
df
----


+*Out[197]:*+
----
[cols=",,,,,,,",options="header",]
|===
| |T |RH |TOW |Prec |SO2 |H+ |CR
|0 |9.50 |79 |2830 |639.30 |77.50 |0.00 |14.89
|1 |10.30 |74 |2555 |380.80 |58.10 |0.02 |6.98
|2 |9.10 |73 |2627 |684.30 |41.20 |0.07 |7.78
|3 |9.80 |77 |3529 |581.10 |32.10 |0.03 |5.69
|4 |7.00 |77 |3011 |850.20 |19.70 |0.00 |8.95
|... |... |... |... |... |... |... |...
|166 |-0.70 |76 |0 |558.00 |10.00 |0.00 |6.35
|167 |-15.50 |68 |0 |306.00 |3.00 |0.00 |1.24
|168 |-0.40 |71 |0 |403.00 |4.00 |0.00 |3.84
|169 |5.00 |79 |0 |570.00 |14.00 |0.00 |7.41
|170 |9.00 |81 |0 |700.00 |3.00 |0.00 |7.03
|===

171 rows × 7 columns
----


+*In[198]:*+
[source, ipython3]
----
#Checking the types of data
df.info()
----


+*Out[198]:*+
----
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 171 entries, 0 to 170
Data columns (total 7 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   T       171 non-null    float64
 1   RH      171 non-null    int64  
 2   TOW     171 non-null    int64  
 3   Prec    171 non-null    float64
 4   SO2     171 non-null    float64
 5   H+      171 non-null    float64
 6   CR      171 non-null    float64
dtypes: float64(5), int64(2)
memory usage: 9.5 KB
----


+*In[199]:*+
[source, ipython3]
----
df.isnull().sum()
----


+*Out[199]:*+
----T       0
RH      0
TOW     0
Prec    0
SO2     0
H+      0
CR      0
dtype: int64----


+*In[200]:*+
[source, ipython3]
----
df.describe()
----


+*Out[200]:*+
----
[cols=",,,,,,,",options="header",]
|===
| |T |RH |TOW |Prec |SO2 |H+ |CR
|count |171.00 |171.00 |171.00 |171.00 |171.00 |171.00 |171.00
|mean |11.04 |72.39 |3121.36 |797.73 |12.31 |0.01 |7.25
|std |7.96 |9.54 |1807.60 |461.34 |16.29 |0.02 |4.95
|min |-16.60 |33.00 |0.00 |17.00 |0.00 |0.00 |0.65
|25% |7.00 |67.50 |2111.00 |525.10 |3.00 |0.00 |4.07
|50% |10.70 |75.00 |3074.00 |679.60 |6.20 |0.00 |6.62
|75% |16.35 |79.00 |4378.50 |974.85 |13.70 |0.03 |9.07
|max |27.00 |98.00 |8760.00 |2624.00 |83.30 |0.19 |27.00
|===
----


+*In[202]:*+
[source, ipython3]
----
!pip install seaborn
----


+*Out[202]:*+
----
Requirement already satisfied: seaborn in c:\users\jasmi\anaconda3\lib\site-packages (0.11.0)
Requirement already satisfied: numpy>=1.15 in c:\users\jasmi\anaconda3\lib\site-packages (from seaborn) (1.19.1)
Requirement already satisfied: scipy>=1.0 in c:\users\jasmi\anaconda3\lib\site-packages (from seaborn) (1.5.4)
Requirement already satisfied: matplotlib>=2.2 in c:\users\jasmi\anaconda3\lib\site-packages (from seaborn) (3.3.2)
Requirement already satisfied: pandas>=0.23 in c:\users\jasmi\anaconda3\lib\site-packages (from seaborn) (1.0.5)
Requirement already satisfied: python-dateutil>=2.1 in c:\users\jasmi\anaconda3\lib\site-packages (from matplotlib>=2.2->seaborn) (2.8.1)
Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\users\jasmi\anaconda3\lib\site-packages (from matplotlib>=2.2->seaborn) (2.4.7)
Requirement already satisfied: cycler>=0.10 in c:\users\jasmi\anaconda3\lib\site-packages (from matplotlib>=2.2->seaborn) (0.10.0)
Requirement already satisfied: kiwisolver>=1.0.1 in c:\users\jasmi\anaconda3\lib\site-packages (from matplotlib>=2.2->seaborn) (1.3.0)
Requirement already satisfied: certifi>=2020.06.20 in c:\users\jasmi\anaconda3\lib\site-packages (from matplotlib>=2.2->seaborn) (2020.6.20)
Requirement already satisfied: pillow>=6.2.0 in c:\users\jasmi\anaconda3\lib\site-packages (from matplotlib>=2.2->seaborn) (8.0.1)
Requirement already satisfied: pytz>=2017.2 in c:\users\jasmi\anaconda3\lib\site-packages (from pandas>=0.23->seaborn) (2020.1)
Requirement already satisfied: six>=1.5 in c:\users\jasmi\anaconda3\lib\site-packages (from python-dateutil>=2.1->matplotlib>=2.2->seaborn) (1.15.0)
----


+*In[203]:*+
[source, ipython3]
----
for col in df.columns.values:
 if col == 'CR':
     continue
 plt.figure(figsize=(20,5))
 sns.scatterplot(df.dropna()[col], df.dropna()['CR'])
 plt.title(col)
 plt.show()
----


+*Out[203]:*+
----
![png](output_6_0.png)

![png](output_6_1.png)

![png](output_6_2.png)

![png](output_6_3.png)

![png](output_6_4.png)

![png](output_6_5.png)
----


+*In[86]:*+
[source, ipython3]
----
sns.regplot(x='RH', y='CR', data=df)
plt.show()
----


+*Out[86]:*+
----
![png](output_7_0.png)
----


+*In[87]:*+
[source, ipython3]
----
sns.regplot(x='TOW', y=CR', data=df)
plt.show()
----


+*Out[87]:*+
----
![png](output_8_0.png)
----


+*In[88]:*+
[source, ipython3]
----
sns.regplot(x='Prec', y='CR', data=df)
plt.show()
----


+*Out[88]:*+
----
![png](output_9_0.png)
----


+*In[89]:*+
[source, ipython3]
----
sns.regplot(x='SO2', y='CR', data=df)
plt.show()
----


+*Out[89]:*+
----
![png](output_10_0.png)
----


+*In[90]:*+
[source, ipython3]
----
sns.regplot(x='H+', y='CR', data=df)
plt.show()
----


+*Out[90]:*+
----
![png](output_11_0.png)
----


+*In[204]:*+
[source, ipython3]
----
sns.pairplot(df)
plt.show()
----


+*Out[204]:*+
----
![png](output_12_0.png)
----


+*In[205]:*+
[source, ipython3]
----
df.corr()
----


+*Out[205]:*+
----
[cols=",,,,,,,",options="header",]
|===
| |T |RH |TOW |Prec |SO2 |H+ |CR
|T |1.00 |-0.16 |0.39 |0.38 |0.04 |-0.16 |0.27
|RH |-0.16 |1.00 |0.63 |0.42 |-0.02 |0.12 |0.40
|TOW |0.39 |0.63 |1.00 |0.60 |-0.02 |0.01 |0.41
|Prec |0.38 |0.42 |0.60 |1.00 |-0.07 |-0.05 |0.42
|SO2 |0.04 |-0.02 |-0.02 |-0.07 |1.00 |0.23 |0.25
|H+ |-0.16 |0.12 |0.01 |-0.05 |0.23 |1.00 |0.01
|CR |0.27 |0.40 |0.41 |0.42 |0.25 |0.01 |1.00
|===
----


+*In[206]:*+
[source, ipython3]
----
#Heatmap (Bi-Variate Analysis)
corr = df.corr()
plt.subplots(figsize=(10,10))
ax = sns.heatmap(
 corr, vmax = 0.8, center = 0,
 linewidths = .01, annot = True,
 cmap = 'RdBu',
 square = True, linecolor='black')
----


+*Out[206]:*+
----
![png](output_14_0.png)
----


+*In[147]:*+
[source, ipython3]
----
# Lazy Predict Scanning Best Model
from pandas import read_csv
from pandas.plotting import scatter_matrix
from matplotlib import pyplot
from sklearn.model_selection import train_test_split
from lazypredict.Supervised import LazyRegressor
from lazypredict.Supervised import LazyClassifier

from lazypredict.Supervised import LazyRegressor
from sklearn import datasets
from sklearn.utils import shuffle
import numpy as np
----


+*In[193]:*+
[source, ipython3]
----
# Load dataset
import pandas as pd
df = pd.read_csv("DATASETJASMITAbismillah.csv")

# Define x and y
X = df.drop(columns='CR')
y = df['CR']

X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=.1,random_state=715)

reg = LazyRegressor(verbose=0,ignore_warnings=False, custom_metric=None )
models,predictions = reg.fit(X_train, X_test, y_train, y_test)

print(models)
----


+*Out[193]:*+
----
100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 26.69it/s]
                               Adjusted R-Squared  R-Squared  RMSE  Time Taken
Model                                                                         
BaggingRegressor                             0.63       0.76  1.97        0.03
ExtraTreesRegressor                          0.50       0.67  2.30        0.14
XGBRegressor                                 0.49       0.67  2.33        0.08
RandomForestRegressor                        0.48       0.67  2.33        0.19
AdaBoostRegressor                            0.44       0.64  2.44        0.09
GradientBoostingRegressor                    0.39       0.61  2.53        0.05
LGBMRegressor                                0.38       0.60  2.57        0.03
OrthogonalMatchingPursuitCV                  0.30       0.55  2.71        0.02
HuberRegressor                               0.29       0.54  2.74        0.02
BayesianRidge                                0.29       0.54  2.74        0.01
RidgeCV                                      0.28       0.54  2.75        0.01
ElasticNetCV                                 0.28       0.54  2.75        0.07
LassoCV                                      0.28       0.54  2.75        0.10
LassoLarsCV                                  0.28       0.54  2.75        0.02
SGDRegressor                                 0.27       0.53  2.77        0.01
LassoLarsIC                                  0.27       0.53  2.78        0.01
Ridge                                        0.27       0.53  2.78        0.01
HistGradientBoostingRegressor                0.26       0.52  2.79        0.11
TransformedTargetRegressor                   0.26       0.52  2.79        0.01
LinearRegression                             0.26       0.52  2.79        0.01
PoissonRegressor                             0.22       0.50  2.86        0.01
LinearSVR                                    0.19       0.47  2.93        0.02
SVR                                          0.16       0.46  2.97        0.01
KNeighborsRegressor                          0.15       0.45  3.00        0.01
TweedieRegressor                             0.14       0.45  3.00        0.01
GeneralizedLinearRegressor                   0.14       0.45  3.00        0.01
NuSVR                                        0.10       0.41  3.09        0.02
RANSACRegressor                              0.06       0.39  3.14        0.06
GammaRegressor                               0.06       0.39  3.15        0.01
ElasticNet                                   0.05       0.39  3.16        0.01
GaussianProcessRegressor                     0.03       0.37  3.20        0.01
DecisionTreeRegressor                        0.01       0.36  3.24        0.01
PassiveAggressiveRegressor                  -0.07       0.31  3.35        0.01
Lars                                        -0.11       0.28  3.42        0.01
Lasso                                       -0.21       0.22  3.57        0.01
LarsCV                                      -0.22       0.21  3.58        0.03
MLPRegressor                                -0.35       0.12  3.78        0.20
OrthogonalMatchingPursuit                   -0.43       0.07  3.89        0.01
LassoLars                                   -0.56      -0.01  4.06        0.01
DummyRegressor                              -0.56      -0.01  4.06        0.01
ExtraTreeRegressor                          -0.96      -0.27  4.55        0.01
KernelRidge                                 -6.37      -3.77  8.82        0.01


----


+*In[ ]:*+
[source, ipython3]
----

----
